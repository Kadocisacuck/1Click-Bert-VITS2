{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "K-nlHfzqf58H",
        "yp1Q3Y1phS8y",
        "RP139P4Qhe18",
        "1eNwA_teGWJO",
        "Cm82HrCCEsGc",
        "qd0z3mBRE22P"
      ],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<a href=\"https://colab.research.google.com/github/sunbooshi/1Click-Bert-VITS2/blob/main/1ClickBertVITS2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ],
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 环境准备\n",
        "\n"
      ],
      "metadata": {
        "id": "K-nlHfzqf58H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 安装Bert-VITS2\n",
        "!git clone https://github.com/fishaudio/Bert-VITS2\n",
        "%cd Bert-VITS2\n",
        "!git checkout v2.3\n",
        "%pip install -r requirements.txt\n",
        "%cd /content/"
      ],
      "metadata": {
        "id": "4bxaVFnKiRIj",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 安装audio-slicer\n",
        "!git clone https://github.com/openvpi/audio-slicer.git audio_slicer"
      ],
      "metadata": {
        "cellView": "form",
        "id": "ydvX6nznf4xU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 安装whisper\n",
        "!pip install git+https://github.com/openai/whisper.git\n",
        "!pip install torchaudio"
      ],
      "metadata": {
        "cellView": "form",
        "id": "zUKEMbS9gNl_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 安装ffmpeg\n",
        "import os, uuid, re, IPython\n",
        "import ipywidgets as widgets\n",
        "import time\n",
        "\n",
        "from glob import glob\n",
        "from google.colab import output, drive\n",
        "\n",
        "from IPython.display import clear_output\n",
        "import os, sys, urllib.request\n",
        "HOME = os.path.expanduser(\"~\")\n",
        "pathDoneCMD = f'{HOME}/doneCMD.sh'\n",
        "if not os.path.exists(f\"{HOME}/.ipython/ttmg.py\"):\n",
        "    hCode = \"https://raw.githubusercontent.com/yunooooo/gcct/master/res/ttmg.py\"\n",
        "    urllib.request.urlretrieve(hCode, f\"{HOME}/.ipython/ttmg.py\")\n",
        "\n",
        "from ttmg import (\n",
        "    loadingAn,\n",
        "    textAn,\n",
        ")\n",
        "\n",
        "loadingAn(name=\"lds\")\n",
        "textAn(\"Cloning Repositories...\", ty='twg')\n",
        "!git clone https://github.com/XniceCraft/ffmpeg-colab.git\n",
        "!chmod 755 ./ffmpeg-colab/install\n",
        "textAn(\"Installing FFmpeg...\", ty='twg')\n",
        "!./ffmpeg-colab/install\n",
        "clear_output()\n",
        "print('Installation finished!')\n",
        "!rm -fr /content/ffmpeg-colab\n",
        "!ffmpeg -version"
      ],
      "metadata": {
        "cellView": "form",
        "id": "j5Rl5ALhgXYi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 准备目录\n",
        "%cd /content/Bert-VITS2/\n",
        "import os\n",
        "data_dir = 'Data'\n",
        "os.mkdir(data_dir)\n",
        "speaker = \"paimeng\" # @param {type:\"string\"}\n",
        "speaker_dir = os.path.join(data_dir, speaker)\n",
        "os.mkdir(speaker_dir)\n",
        "audios = os.path.join(speaker_dir, 'audios')\n",
        "os.mkdir(audios)\n",
        "audios_raw = os.path.join(audios, 'raw')\n",
        "os.mkdir(audios_raw)\n",
        "audios_wavs = os.path.join(audios, 'wavs')\n",
        "os.mkdir(audios_wavs)\n",
        "filelists = os.path.join(speaker_dir, 'filelists')\n",
        "os.mkdir(filelists)\n",
        "input_dir = \"inputs\"\n",
        "os.mkdir(input_dir)\n",
        "models_dir = os.path.join(speaker_dir, 'models')\n",
        "os.mkdir(models_dir)"
      ],
      "metadata": {
        "id": "tvcYwiQAggHe",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 模型下载"
      ],
      "metadata": {
        "id": "yp1Q3Y1phS8y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 下载模型\n",
        "!wget -P slm/wavlm-base-plus/ https://huggingface.co/microsoft/wavlm-base-plus/resolve/main/pytorch_model.bin\n",
        "!wget -P emotional/clap-htsat-fused/ https://huggingface.co/laion/clap-htsat-fused/resolve/main/pytorch_model.bin\n",
        "!wget -P emotional/wav2vec2-large-robust-12-ft-emotion-msp-dim/ https://huggingface.co/audeering/wav2vec2-large-robust-12-ft-emotion-msp-dim/resolve/main/pytorch_model.bin\n",
        "!wget -P bert/chinese-roberta-wwm-ext-large/ https://huggingface.co/hfl/chinese-roberta-wwm-ext-large/resolve/main/pytorch_model.bin\n",
        "!wget -P bert/bert-base-japanese-v3/ https://huggingface.co/cl-tohoku/bert-base-japanese-v3/resolve/main/pytorch_model.bin\n",
        "!wget -P bert/deberta-v3-large/ https://huggingface.co/microsoft/deberta-v3-large/resolve/main/pytorch_model.bin\n",
        "!wget -P bert/deberta-v3-large/ https://huggingface.co/microsoft/deberta-v3-large/resolve/main/pytorch_model.generator.bin\n",
        "!wget -P bert/deberta-v2-large-japanese/ https://huggingface.co/ku-nlp/deberta-v2-large-japanese/resolve/main/pytorch_model.bin"
      ],
      "metadata": {
        "id": "5XQuP0IdHTkx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 训练底模\n",
        "!wget -P $models_dir https://huggingface.co/OedoSoldier/Bert-VITS2-2.3/resolve/main/DUR_0.pth\n",
        "!wget -P $models_dir https://huggingface.co/OedoSoldier/Bert-VITS2-2.3/resolve/main/D_0.pth\n",
        "!wget -P $models_dir https://huggingface.co/OedoSoldier/Bert-VITS2-2.3/resolve/main/G_0.pth\n",
        "!wget -P $models_dir https://huggingface.co/OedoSoldier/Bert-VITS2-2.3/resolve/main/WD_0.pth"
      ],
      "metadata": {
        "id": "D_LfuzFbHeib"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 准备训练数据"
      ],
      "metadata": {
        "id": "RP139P4Qhe18"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 上传训练数据"
      ],
      "metadata": {
        "id": "h4hhxVLUhm1O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ### 直接上传\n",
        "import shutil\n",
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for f in uploaded.keys():\n",
        "  shutil.move(f, input_dir)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "15b2TdwziBi8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 从GoogleDrive 复制"
      ],
      "metadata": {
        "id": "4wyfuXDueEeT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title #### 挂载GoogleDrive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "LYlkjDLZhyM4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title #### 复制文件\n",
        "import shutil\n",
        "# @markdown  输入要复制的文件路径：\n",
        "drive_path = \"/content/drive/MyDrive/data/paimeng.wav\" # @param {type:\"string\"}\n",
        "if os.path.isdir(drive_path):\n",
        "  !cp {drive_path}*.wav {input_dir}\n",
        "else:\n",
        "  !cp {drive_path} {input_dir}"
      ],
      "metadata": {
        "id": "rkqEVVqrePkH",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 数据处理"
      ],
      "metadata": {
        "id": "N1eleBAgGFh3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ### 音频分割\n",
        "import librosa  # Optional. Use any library you like to read audio files.\n",
        "import soundfile  # Optional. Use any library you like to write audio files.\n",
        "import os\n",
        "import sys\n",
        "sys.path.append('/content/audio_slicer')\n",
        "from slicer2 import Slicer\n",
        "\n",
        "def slice_audio(in_file, out_path, out_name, base_index=0):\n",
        "    audio, sr = librosa.load(in_file, sr=None, mono=False)  # Load an audio file with librosa.\n",
        "    slicer = Slicer(\n",
        "        sr=sr,\n",
        "        threshold=-40,\n",
        "        min_length=2000,\n",
        "        min_interval=300,\n",
        "        hop_size=10,\n",
        "        max_sil_kept=500\n",
        "    )\n",
        "    chunks = slicer.slice(audio)\n",
        "    total = 0\n",
        "    for i, chunk in enumerate(chunks):\n",
        "        total = total + 1\n",
        "        if len(chunk.shape) > 1:\n",
        "            chunk = chunk.T  # Swap axes if the audio is stereo.\n",
        "        out_file = os.path.join(out_path, '%s_%03d.wav' % (out_name, base_index+i))\n",
        "        soundfile.write(out_file, chunk, sr)  # Save sliced audio files with soundfile.\n",
        "\n",
        "    return total\n",
        "\n",
        "def slice_dir(input_dir, output_dir, model_name):\n",
        "    # 列出当前工作目录中的所有文件和文件夹\n",
        "    files = os.listdir(input_dir)\n",
        "\n",
        "    base_index = 0\n",
        "    # 筛选出所有以 \".wav\" 结尾的文件\n",
        "    wav_files = [f for f in files if f.endswith(\".wav\")]\n",
        "\n",
        "    # 打印所有 wav 文件的名称\n",
        "    for f in wav_files:\n",
        "        base_index = base_index + slice_audio(os.path.join(input_dir, f), output_dir, model_name, base_index)\n",
        "\n",
        "\n",
        "if len(input_dir)>0 and len(audios_raw)>0 and len(speaker)>0:\n",
        "  slice_dir(input_dir, audios_raw, speaker)\n",
        "else:\n",
        "  print(\"error input\")\n",
        "\n",
        "print(\"分割完成\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "llFeG-tdIAwE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ### 音频标注\n",
        "\n",
        "import whisper\n",
        "import os\n",
        "import json\n",
        "import torchaudio\n",
        "import argparse\n",
        "import torch\n",
        "\n",
        "lang2token = {\n",
        "            'zh': \"ZH|\",\n",
        "            'ja': \"JP|\",\n",
        "            \"en\": \"EN|\",\n",
        "        }\n",
        "\n",
        "def transcribe(audio_path):\n",
        "    # load audio and pad/trim it to fit 30 seconds\n",
        "    audio = whisper.load_audio(audio_path)\n",
        "    audio = whisper.pad_or_trim(audio)\n",
        "\n",
        "    # make log-Mel spectrogram and move to the same device as the model\n",
        "    mel = whisper.log_mel_spectrogram(audio).to(model.device)\n",
        "\n",
        "    # detect the spoken language\n",
        "    _, probs = model.detect_language(mel)\n",
        "    print(f\"Detected language: {max(probs, key=probs.get)}\")\n",
        "    lang = max(probs, key=probs.get)\n",
        "    # decode the audio\n",
        "    options = whisper.DecodingOptions(beam_size=5)\n",
        "    result = whisper.decode(model, mel, options)\n",
        "\n",
        "    # print the recognized text\n",
        "    print(result.text)\n",
        "    return lang, result.text\n",
        "\n",
        "\n",
        "# assert (torch.cuda.is_available()), \"Please enable GPU in order to run Whisper!\"\n",
        "model = whisper.load_model(\"medium\")\n",
        "speaker_annos = []\n",
        "total_files = sum([len(files) for r, d, files in os.walk(audios_raw)])\n",
        "processed_files = 0\n",
        "\n",
        "for i, wavfile in enumerate(list(os.walk(audios_raw))[0][2]):\n",
        "    # try to load file as audio\n",
        "    try:\n",
        "        lang, text = transcribe(os.path.join(audios_raw, wavfile))\n",
        "        if lang not in list(lang2token.keys()):\n",
        "            print(f\"{lang} not supported, ignoring\\n\")\n",
        "            continue\n",
        "\n",
        "        text = f\"{audios_wavs}/{wavfile}|\" + f\"{speaker}|\" +lang2token[lang] + text + \"\\n\"\n",
        "        speaker_annos.append(text)\n",
        "\n",
        "        processed_files += 1\n",
        "        print(f\"Processed: {processed_files}/{total_files}\")\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        continue\n",
        "\n",
        "if len(speaker_annos) == 0:\n",
        "    print(\"Warning: no short audios found, this IS expected if you have only uploaded long audios, videos or video links.\")\n",
        "    print(\"this IS NOT expected if you have uploaded a zip file of short audios. Please check your file structure or make sure your audio language is supported.\")\n",
        "with open(os.path.join(filelists, 'esd.list'), 'w', encoding='utf-8') as f:\n",
        "    for line in speaker_annos:\n",
        "        f.write(line)\n",
        "\n",
        "print(\"标注完成\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "fgpCz0pyHRpp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ### 配置文件生成\n",
        "log_interval = 50 # @param {type:\"integer\"}\n",
        "eval_interval = 100 # @param {type:\"integer\"}\n",
        "epochs = 100 # @param {type:\"integer\"}\n",
        "batch_size = 4 # @param {type:\"integer\"}\n",
        "bert_device = \"cuda\" # @param [\"cuda\", \"cpu\"]\n",
        "bert_processs = 2 # @param {type:\"integer\"}\n",
        "\n",
        "import json\n",
        "with open('configs/config.json') as fp:\n",
        "  configs = json.load(fp)\n",
        "\n",
        "configs['train']['log_interval'] = log_interval\n",
        "configs['train']['eval_interval'] = eval_interval\n",
        "configs['train']['epochs'] = epochs\n",
        "configs['train']['batch_size'] = batch_size\n",
        "\n",
        "configs['data']['training_files'] = os.path.join(filelists, 'train.list')\n",
        "configs['data']['validation_files'] = os.path.join(filelists, 'val.list')\n",
        "configs['data']['n_speakers'] = 1\n",
        "configs['data']['spk2id'] = {speaker : 0}\n",
        "\n",
        "configs_path = os.path.join(speaker_dir, 'config.json')\n",
        "with open(configs_path, 'w') as fp:\n",
        "  json.dump(configs, fp, indent=4)\n",
        "  print(f'生成配置文件: {configs_path}')\n",
        "\n",
        "configs = None\n",
        "import yaml\n",
        "with open('default_config.yml') as fp:\n",
        "  configs = yaml.load(fp, Loader=yaml.FullLoader)\n",
        "\n",
        "configs['dataset_path'] = speaker_dir\n",
        "configs['preprocess_text']['transcription_path'] = 'filelists/esd.list'\n",
        "configs['bert_gen']['device'] = bert_device\n",
        "configs['bert_gen']['num_processes'] = bert_processs\n",
        "\n",
        "with open('config.yml', 'w') as fp:\n",
        "  yaml.dump(configs, fp)\n",
        "  print(f'生成配置文件: config.yml')"
      ],
      "metadata": {
        "id": "BBzWZmTjfhei"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 音频重采样\n",
        "!python resample.py"
      ],
      "metadata": {
        "cellView": "form",
        "id": "4XFx-6PLEWER"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 生成训练集、验证集\n",
        "!python preprocess_text.py"
      ],
      "metadata": {
        "cellView": "form",
        "id": "CMZG8FyzEc-T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 生成Bert\n",
        "!python bert_gen.py"
      ],
      "metadata": {
        "cellView": "form",
        "id": "ZJImUsCcEjWH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tensorboard"
      ],
      "metadata": {
        "id": "1eNwA_teGWJO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir $models_dir"
      ],
      "metadata": {
        "id": "a7Q6byqrGVP-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 训练"
      ],
      "metadata": {
        "id": "Cm82HrCCEsGc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python train_ms.py"
      ],
      "metadata": {
        "id": "lvwcObnfEukD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 推理"
      ],
      "metadata": {
        "id": "qd0z3mBRE22P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = \"G_1000.pth\" # @param {type:\"string\"}\n",
        "\n",
        "configs = None\n",
        "import yaml\n",
        "with open('config.yml') as fp:\n",
        "  configs = yaml.load(fp, Loader=yaml.FullLoader)\n",
        "  configs['webui']['model'] = f'models/{model}'\n",
        "  configs['webui']['share'] = True\n",
        "\n",
        "with open('config.yml', 'w') as fp:\n",
        "  yaml.dump(configs, fp)\n",
        "  print(f'更新配置文件: config.yml')\n",
        "\n",
        "print('启动webui')\n",
        "!python webui.py"
      ],
      "metadata": {
        "id": "38Ns5KRGE8zW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
